#LyX 2.0 created this file. For more info see http://www.lyx.org/
\lyxformat 413
\begin_document
\begin_header
\textclass extarticle
\options latin9
\use_default_options false
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry true
\use_amsmath 0
\use_esint 0
\use_mhchem 1
\use_mathdots 1
\cite_engine basic
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\use_refstyle 0
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 1in
\topmargin 1in
\rightmargin 1in
\bottommargin 1in
\headheight 1in
\headsep 1in
\footskip 1in
\columnsep 1in
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Problem Set #3
\end_layout

\begin_layout Author
Omer Hazon
\end_layout

\begin_layout Section
A Simple Neural Network
\end_layout

\begin_layout Subsection*
(a)
\end_layout

\begin_layout Standard
Defining the delta vectors:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\delta^{[2]}=\nabla_{w_{0}^{[2]}}J=\nabla_{o}(o-y)^{2}\circ\sigma'(z^{[2]})=2(o-y)\circ o(1-o)=2(o-y)o(1-o)
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\nabla_{w^{[2]}}J=\delta^{[2]}a^{[1]T}=\delta^{[2]}h^{T}=2(o-y)o(1-o)h^{T}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\delta^{[1]}=\nabla_{w_{0}^{[1]}}J=\left(w^{[2]T}\delta^{[2]}\right)\circ\sigma'(z^{[1]})=\left(w^{[2]T}2(o-y)o(1-o)\right)\circ h\circ(1-h)=
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=2(o-y)o(1-o)w^{[2]T}\circ h\circ(1-h)
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\nabla_{w^{[1]}}J=\delta^{[1]}a^{[0]T}=\left(2(o-y)o(1-o)w^{[2]T}\circ h\circ(1-h)\right)x^{T}
\]

\end_inset


\end_layout

\begin_layout Standard
The (1,2) component of the above is:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\left[\left(2(o-y)o(1-o)w^{[2]T}\circ h\circ(1-h)\right)x^{T}\right]_{1,2}=\left(2(o-y)o(1-o)w^{[2]T}\circ h\circ(1-h)\right)_{1}x_{2}=
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=\left(2(o-y)o(1-o)w_{1}^{[2]T}h_{1}(1-h_{1})\right)x_{2}=2(o-y)o(1-o)w_{1}^{[2]}h_{1}(1-h_{1})x_{2}
\]

\end_inset


\end_layout

\begin_layout Standard
And so the full gradient descent step is:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
w_{1,2}^{[1]}\leftarrow w_{1,2}^{[1]}-\frac{\alpha}{m}\sum_{i=1}^{m}2(o^{(i)}-y^{(i)})o^{(i)}(1-o^{(i)})w_{1}^{[2]}h_{1}^{(i)}(1-h_{1}^{(i)})x_{2}^{(i)}
\]

\end_inset


\end_layout

\begin_layout Standard
The value of 
\begin_inset Formula $h_{1}^{(i)}$
\end_inset

 in terms of x and weigths is 
\begin_inset Formula $h_{1}^{(i)}=\sigma(w_{:,1}^{[1]T}x^{(i)}+w_{0,1}^{[1]})$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
w_{1,2}^{[1]}\leftarrow w_{1,2}^{[1]}-2\frac{\alpha}{m}\sum_{i=1}^{m}(o^{(i)}-y^{(i)})o^{(i)}(1-o^{(i)})w_{1}^{[2]}\sigma(w_{:,1}^{[1]T}x^{(i)}+w_{0,1}^{[1]})\left(1-\sigma(w_{:,1}^{[1]T}x^{(i)}+w_{0,1}^{[1]})\right)x_{2}^{(i)}
\]

\end_inset


\end_layout

\begin_layout Subsection*
(b)
\end_layout

\begin_layout Standard
The first layer comprises of three linear separations.
 These three linear separations can then be combined to distinguish between
 the inside and outside of the triangle.
\end_layout

\begin_layout Standard
The form of the linear separation equation is 
\begin_inset Formula $w_{0}+w_{1}x_{1}+w_{2}x_{2}=0$
\end_inset

.
\end_layout

\begin_layout Standard
The three vertices of the triangle are approximately at the points defined
 by the rows of the following matrix, found by closely analyzing the pixels
 in the given figure:
\end_layout

\begin_layout Standard
\begin_inset listings
inline false
status open

\begin_layout Plain Layout

   0.31978   0.37050
\end_layout

\begin_layout Plain Layout

   0.31978   3.95197
\end_layout

\begin_layout Plain Layout

   3.73442   0.37050 
\end_layout

\end_inset


\end_layout

\begin_layout Standard
A line between two points 
\begin_inset Formula $(x_{1},y_{1}),(x_{2},y_{2})$
\end_inset

 is given by the equation:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
w_{0}+w_{1}x+w_{2}y=(x_{1}y_{2}-y_{1}x_{2})+(y_{1}-y_{2})x+(x_{2}-x_{1})y=0
\]

\end_inset


\end_layout

\begin_layout Standard
Applying this formula to each pair of points, gives three sets of weights:
\end_layout

\begin_layout Standard
\begin_inset listings
inline false
status open

\begin_layout Plain Layout

w0: -1.145296  w1:  3.581475 w2: 0.000000
\end_layout

\begin_layout Plain Layout

w0: -1.265113  w1:  0.000000 w2: 3.414634
\end_layout

\begin_layout Plain Layout

w0: -14.639836 w1:  3.581475 w2: 3.414634 
\end_layout

\end_inset


\end_layout

\begin_layout Standard
And by visualizing the inequalities created by the edges of the triangle,
 the following second layer weights were chosen:
\end_layout

\begin_layout Standard
\begin_inset listings
inline false
status open

\begin_layout Plain Layout

bias: 1.5, weights: (-1, -1, +1)
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename p1nn.png
	scale 75

\end_inset


\end_layout

\begin_layout Standard
In the language of the problem, the weights assigned to the network are:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
w_{0,1}^{[1]}=-1.145296,w_{1,1}^{[1]}=3.581475,w_{2,1}^{[1]}=0
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
w_{0,2}^{[1]}=-1.265113,w_{1,2}^{[1]}=0,w_{2,2}^{[1]}=3.414634
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
w_{0,3}^{[1]}=-14.639836,w_{1,3}^{[1]}=3.581475,w_{2,3}^{[1]}=3.414634
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
w_{0}^{[2]}=1.5,w_{1}^{[2]}=-1,w_{2}^{[2]}=-1,w_{3}^{[2]}=1
\]

\end_inset


\end_layout

\begin_layout Subsection*
(c)
\end_layout

\begin_layout Standard
Such weights do not exist, since in that case the output amounts to a step
 function over a linear function of the input (with bias).
 This is identical to just a single layer, and represents a linear separation
 of the data.
 The data is not linearly seperable and therefore such weights do not exist.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
f\left(w^{[2]}\left(w^{[1]}x+w_{0}^{[1]}\right)+w_{0}^{[2]}\right)=f\left(\left(w^{[2]}w^{[1]}\right)x+\left(w^{[2]}w_{0}^{[1]}+w_{0}^{[2]}\right)\right)
\]

\end_inset


\end_layout

\begin_layout Section
EM for MAP estimation
\end_layout

\begin_layout Standard
We wish to maximize:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
p(\theta)\prod_{i=1}^{m}p(x^{(i)}\mid\theta)=p(\theta)\left(\prod_{i=1}^{m}\sum_{z^{(i)}}p(x^{(i)},z^{(i)}\mid\theta)\right)
\]

\end_inset


\end_layout

\begin_layout Standard
Taking the log:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\log p(\theta)+\sum_{i=1}^{m}\log p(x^{(i)}\mid\theta)=\log p(\theta)+\sum_{i=1}^{m}\log\left(\sum_{z^{(i)}}p(x^{(i)},z^{(i)}\mid\theta)\right)=
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\log p(\theta)+\sum_{i=1}^{m}\log\left(\sum_{z^{(i)}}Q_{i}(z^{(i)})\frac{p(x^{(i)},z^{(i)}\mid\theta)}{Q_{i}(z^{(i)})}\right)\ge\log p(\theta)+\sum_{i=1}^{m}\sum_{z^{(i)}}Q_{i}(z^{(i)})\log\left(\frac{p(x^{(i)},z^{(i)}\mid\theta)}{Q_{i}(z^{(i)})}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
By the concavity of the log function and Jensen's inequality.
 The expectation of the log over the distribution 
\begin_inset Formula $Q_{i}(z^{(i)})$
\end_inset

 is lesser or equal to the log of the expectation.
\end_layout

\begin_layout Standard
Let the E-step consist of setting the Q's such that Jensen's inequality
 holds with equality, that is, that 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
Q_{i}(z^{(i)})\propto p(x^{(i)},z^{(i)}\mid\theta)\rightarrow^{\text{implies}}Q_{i}(z^{(i)})=\frac{p(x^{(i)},z^{(i)}\mid\theta)}{\sum_{z}p(x^{(i)},z\mid\theta)}=\frac{p(x^{(i)},z^{(i)}\mid\theta)}{p(x^{(i)}\mid\theta)}=p(z^{(i)}\mid x^{(i)},\theta)
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
Q_{i}(z^{(i)})\leftarrow p(z^{(i)}\mid x^{(i)},\theta)
\]

\end_inset


\end_layout

\begin_layout Standard
And let the M-step consist of maximizing the right hand side of the inequality,
 which starts out being equal with the initial value of 
\begin_inset Formula $\theta$
\end_inset

 but ends up being less than the left hand side.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\theta\leftarrow\arg\max_{\theta}\left[\log p(\theta)+\sum_{i=1}^{m}\sum_{z^{(i)}}Q_{i}(z^{(i)})\log\left(\frac{p(x^{(i)},z^{(i)}\mid\theta)}{Q_{i}(z^{(i)})}\right)\right]
\]

\end_inset


\end_layout

\begin_layout Standard
This amounts to maximizing a linear combination of 
\begin_inset Formula $\log p(\theta)$
\end_inset

 and 
\begin_inset Formula $\log p(x,z\mid\theta)$
\end_inset

 with various inputs for x and z.
 These are assumed to be concave in 
\begin_inset Formula $\theta$
\end_inset

 and therefore the maximization of their linear combination is tractable.
\end_layout

\begin_layout Standard
To prove that 
\begin_inset Formula $p(\theta)\prod_{i=1}^{m}p(x^{(i)}\mid\theta)==p(\theta)\left(\prod_{i=1}^{m}\sum_{z^{(i)}}p(x^{(i)},z^{(i)}\mid\theta)\right)$
\end_inset

 monotonically increases with each update of 
\begin_inset Formula $\theta$
\end_inset

, we look at its log, 
\begin_inset Formula $\log p(\theta)+\sum_{i=1}^{m}\log\left(\sum_{z^{(i)}}p(x^{(i)},z^{(i)}\mid\theta)\right)$
\end_inset

 and use Jensen's inequality from above.
\end_layout

\begin_layout Standard
Given any value of 
\begin_inset Formula $\theta$
\end_inset

 from step 
\begin_inset Formula $t$
\end_inset

 of the EM-MAP algorithm, that is, the value 
\begin_inset Formula $\theta^{(t)}$
\end_inset

, we arrive at the value of the log-probability as:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\log p(\theta^{(t)})+\sum_{i=1}^{m}\log\left(\sum_{z^{(i)}}p(x^{(i)},z^{(i)}\mid\theta^{(t)})\right)
\]

\end_inset


\end_layout

\begin_layout Standard
Applying EM-MAP, we arrive at 
\begin_inset Formula 
\[
Q_{i}^{(t)}(z^{(i)})\leftarrow p(z^{(i)}\mid x^{(i)},\theta^{(t)})
\]

\end_inset


\end_layout

\begin_layout Standard
And then to
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\theta^{(t+1)}=\arg\max_{\theta}\left[\log p(\theta)+\sum_{i=1}^{m}\sum_{z^{(i)}}p(z^{(i)}\mid x^{(i)},\theta^{(t)})\log\left(\frac{p(x^{(i)},z^{(i)}\mid\theta)}{p(z^{(i)}\mid x^{(i)},\theta^{(t)})}\right)\right]
\]

\end_inset


\end_layout

\begin_layout Standard
It is known that by design,
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\log p(\theta^{(t)})+\sum_{i=1}^{m}\sum_{z^{(i)}}p(z^{(i)}\mid x^{(i)},\theta^{(t)})\log\left(\frac{p(x^{(i)},z^{(i)}\mid\theta^{(t)})}{p(z^{(i)}\mid x^{(i)},\theta^{(t)})}\right)=\log p(\theta^{(t)})+\sum_{i=1}^{m}\log\sum_{z^{(i)}}p(x^{(i)},z^{(i)}\mid\theta^{(t)})
\]

\end_inset


\end_layout

\begin_layout Standard
And due to the maximization step,
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\log p(\theta^{(t+1)})+\sum_{i=1}^{m}\sum_{z^{(i)}}p(z^{(i)}\mid x^{(i)},\theta^{(t)})\log\left(\frac{p(x^{(i)},z^{(i)}\mid\theta^{(t+1)})}{p(z^{(i)}\mid x^{(i)},\theta^{(t)})}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\ge\log p(\theta^{(t)})+\sum_{i=1}^{m}\sum_{z^{(i)}}p(z^{(i)}\mid x^{(i)},\theta^{(t)})\log\left(\frac{p(x^{(i)},z^{(i)}\mid\theta^{(t)})}{p(z^{(i)}\mid x^{(i)},\theta^{(t)})}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
By the equality above,
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\log p(\theta^{(t+1)})+\sum_{i=1}^{m}\sum_{z^{(i)}}p(z^{(i)}\mid x^{(i)},\theta^{(t)})\log\left(\frac{p(x^{(i)},z^{(i)}\mid\theta^{(t+1)})}{p(z^{(i)}\mid x^{(i)},\theta^{(t)})}\right)\ge\log p(\theta^{(t)})+\sum_{i=1}^{m}\log\sum_{z^{(i)}}p(x^{(i)},z^{(i)}\mid\theta^{(t)})
\]

\end_inset


\end_layout

\begin_layout Standard
And by Jensen's inequality,
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\log p(\theta^{(t+1)})+\sum_{i=1}^{m}\log\sum_{z^{(i)}}p(x^{(i)},z^{(i)}\mid\theta^{(t+1)})\ge\log p(\theta^{(t+1)})+\sum_{i=1}^{m}\sum_{z^{(i)}}p(z^{(i)}\mid x^{(i)},\theta^{(t)})\log\left(\frac{p(x^{(i)},z^{(i)}\mid\theta^{(t+1)})}{p(z^{(i)}\mid x^{(i)},\theta^{(t)})}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
Therefore, putting together the two inequalities,
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\log p(\theta^{(t+1)})+\sum_{i=1}^{m}\log\sum_{z^{(i)}}p(x^{(i)},z^{(i)}\mid\theta^{(t+1)})\ge\log p(\theta^{(t)})+\sum_{i=1}^{m}\log\sum_{z^{(i)}}p(x^{(i)},z^{(i)}\mid\theta^{(t)})
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\log p(\theta^{(t+1)})+\sum_{i=1}^{m}\log p(x^{(i)}\mid\theta^{(t+1)})\ge\log p(\theta^{(t)})+\sum_{i=1}^{m}\log p(x^{(i)}\mid\theta^{(t)})
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
p(\theta^{(t+1)})\prod_{i=1}^{m}p(x^{(i)}\mid\theta^{(t+1)})\ge p(\theta^{(t)})\prod_{i=1}^{m}p(x^{(i)}\mid\theta^{(t)})
\]

\end_inset


\end_layout

\begin_layout Standard
And the desired quantity increases monotonically upon application of an
 EM-MAP step.
\end_layout

\begin_layout Section
EM Application
\end_layout

\begin_layout Subsection*
(a)
\end_layout

\begin_layout Subsubsection*
(i)
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
p(y^{(pr)},z^{(pr)},x^{(pr)})=p(x^{(pr)}\mid y^{(pr)},z^{(pr)})p(y^{(pr)})p(z^{(pr)})=
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\frac{1}{\sqrt{2\pi\sigma^{2}}}\exp\left(-\frac{(x^{(pr)}-y^{(pr)}-z^{(pr)})^{2}}{2\sigma^{2}}\right)\frac{1}{\sqrt{2\pi\sigma_{p}^{2}}}\exp\left(-\frac{(y^{(pr)}-\mu_{p})^{2}}{2\sigma_{p}^{2}}\right)\frac{1}{\sqrt{2\pi\tau_{r}^{2}}}\exp\left(-\frac{(z^{(pr)}-\nu_{r})^{2}}{2\tau_{r}^{2}}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
If you assume that the total distribution has the form of a multivariate
 gaussian, then it is possible to reason about the mean and covariance matrix.
 The means of 
\begin_inset Formula $y^{(pr)}$
\end_inset

 and 
\begin_inset Formula $z^{(pr)}$
\end_inset

 will be the same as before, 
\begin_inset Formula $\mu_{p}$
\end_inset

 and 
\begin_inset Formula $\nu_{r}$
\end_inset

, respectively, and the mean of 
\begin_inset Formula $x^{(pr)}$
\end_inset

 will remain 
\begin_inset Formula $\mu_{p}+\nu_{r}$
\end_inset

.
 The diagonals of the covariance matrix will be the same as the variance
 of the univariate distributions for 
\begin_inset Formula $y^{(pr)}$
\end_inset

 and 
\begin_inset Formula $z^{(pr)}$
\end_inset

, being 
\begin_inset Formula $\sigma_{p}^{2}$
\end_inset

 and 
\begin_inset Formula $\tau_{r}^{2}$
\end_inset

 respectively, while for 
\begin_inset Formula $x^{(pr)}$
\end_inset

 since we are interested in the uncoditional probabilities, we cannot state
 that the variance is 
\begin_inset Formula $\sigma^{2}$
\end_inset

.
 Instead view 
\begin_inset Formula $x^{(pr)}$
\end_inset

 as the sum of the random variables 
\begin_inset Formula $y^{(pr)}+z^{(pr)}+\epsilon^{(pr)}$
\end_inset

 where 
\begin_inset Formula $\epsilon^{(pr)}\sim N(0,\sigma^{2})$
\end_inset

 is uncorrelated.
 Then the variance of 
\begin_inset Formula $x^{(pr)}$
\end_inset

 will be the sum of the variances 
\begin_inset Formula $\sigma_{p}^{2}+\tau_{r}^{2}+\sigma^{2}$
\end_inset

.
 As for the off-diagonal terms, 
\begin_inset Formula $y^{(pr)}$
\end_inset

 and 
\begin_inset Formula $z^{(pr)}$
\end_inset

 are independent and do not covary, while for the off-diagonal terms involving
 
\begin_inset Formula $x^{(pr)}$
\end_inset

 the covariance will come from the term in the random-variable-sum that
 is not independent from the covariant, that is, the covariance of 
\begin_inset Formula $x^{(pr)}$
\end_inset

 with 
\begin_inset Formula $y^{(pr)}$
\end_inset

 is identical to the covariance of 
\begin_inset Formula $y^{(pr)}$
\end_inset

 and 
\begin_inset Formula $y^{(pr)}$
\end_inset

, or 
\begin_inset Formula $\sigma_{p}^{2}$
\end_inset

, and similarly for the covariance between 
\begin_inset Formula $x^{(pr)}$
\end_inset

 and 
\begin_inset Formula $z^{(pr)}$
\end_inset

, it will be 
\begin_inset Formula $\tau_{r}^{2}$
\end_inset

.
\end_layout

\begin_layout Standard
In summary, the mean vector is (using the ordering 
\begin_inset Formula $[x,y,z]^{T}$
\end_inset

):
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\boldsymbol{\mu}=\left[\begin{array}{c}
\mu_{p}+\nu_{r}\\
\mu_{p}\\
\nu_{r}
\end{array}\right]
\]

\end_inset


\end_layout

\begin_layout Standard
And the covariance matrix is:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\boldsymbol{\Sigma}=\left[\begin{array}{ccc}
\sigma^{2}+\sigma_{p}^{2}+\tau_{r}^{2} & \sigma_{p}^{2} & \tau_{r}^{2}\\
\sigma_{p}^{2} & \sigma_{p}^{2} & 0\\
\tau_{r}^{2} & 0 & \tau_{r}^{2}
\end{array}\right]
\]

\end_inset


\end_layout

\begin_layout Subsubsection*
(ii) 
\end_layout

\begin_layout Standard
Taking the conditional over 
\begin_inset Formula $x^{(pr)}$
\end_inset

 to get the mean vector and covariance matrix of 
\begin_inset Formula $Q_{pr}(y^{(pr)},z^{(pr)})=p(y^{(pr)},z^{(pr)}\mid x^{(pr)})$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
Q_{pr}(y^{(pr)},z^{(pr)})=\det(2\pi\bar{\Sigma})^{-1/2}\exp\left(-\frac{1}{2}(\left[\begin{array}{c}
y^{(pr)}\\
z^{(pr)}
\end{array}\right]-\bar{\mu})^{T}\bar{\Sigma}^{-1}(\left[\begin{array}{c}
y^{(pr)}\\
z^{(pr)}
\end{array}\right]-\bar{\mu})\right)
\]

\end_inset


\end_layout

\begin_layout Standard
With 
\begin_inset Formula $\bar{\mu},\bar{\Sigma}$
\end_inset

 defined by:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\bar{\mu}:=\mu_{y^{(pr)},z^{(pr)}\mid x^{(pr)}}=\mu_{y^{(pr)},z^{(pr)}}+\Sigma_{\left(y^{(pr)},z^{(pr)}\right),x^{(pr)}}\Sigma_{x^{(pr)},x^{(pr)}}^{-1}\left(x^{(pr)}-\mu_{x^{(pr)}}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=\left[\begin{array}{c}
\mu_{p}\\
\nu_{r}
\end{array}\right]+\left[\begin{array}{c}
\sigma_{p}^{2}\\
\tau_{r}^{2}
\end{array}\right]\frac{1}{\sigma^{2}+\sigma_{p}^{2}+\tau_{r}^{2}}\left(x^{(pr)}-\mu_{p}-\nu_{r}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\bar{\Sigma}:=\Sigma_{\left(y^{(pr)},z^{(pr)}\right)\mid x^{(pr)}}=\Sigma_{\left(y^{(pr)},z^{(pr)}\right),\left(y^{(pr)},z^{(pr)}\right)}-\Sigma_{\left(y^{(pr)},z^{(pr)}\right),x^{(pr)}}\Sigma_{x^{(pr)},x^{(pr)}}^{-1}\Sigma_{x^{(pr)},\left(y^{(pr)},z^{(pr)}\right)}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=\left[\begin{array}{cc}
\sigma_{p}^{2} & 0\\
0 & \tau_{r}^{2}
\end{array}\right]-\left[\begin{array}{c}
\sigma_{p}^{2}\\
\tau_{r}^{2}
\end{array}\right]\frac{1}{\sigma^{2}+\sigma_{p}^{2}+\tau_{r}^{2}}\left[\begin{array}{cc}
\sigma_{p}^{2} & \tau_{r}^{2}\end{array}\right]
\]

\end_inset


\end_layout

\begin_layout Subsection*
(b)
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\arg\max_{\mu_{p},\nu_{r},\sigma_{p}^{2},\tau_{r}^{2}}\sum_{p}\sum_{r}\mathbb{E}_{(y^{(pr)},z^{(pr)})\sim Q_{pr}}\left[\log\left(\frac{p(y^{(pr)},z^{(pr)},x^{(pr)};\mu_{p},\nu_{r},\sigma_{p}^{2},\tau_{r}^{2})}{Q_{pr}(y^{(pr)},z^{(pr)})}\right)\right]=
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=\arg\max_{\mu_{p},\nu_{r},\sigma_{p}^{2},\tau_{r}^{2}}\sum_{p}\sum_{r}\mathbb{E}_{(y^{(pr)},z^{(pr)})\sim Q_{pr}}\log\left(p(y^{(pr)},z^{(pr)},x^{(pr)};\mu_{p},\nu_{r},\sigma_{p}^{2},\tau_{r}^{2})\right)=
\]

\end_inset


\end_layout

\begin_layout Standard
Where
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
p(y^{(pr)},z^{(pr)},x^{(pr)};\mu_{p},\nu_{r},\sigma_{p}^{2},\tau_{r}^{2})=\det\left(2\pi\boldsymbol{\Sigma}\right)^{-\frac{1}{2}}\exp\left(-\frac{1}{2}\left(\left[\begin{array}{c}
x^{(pr)}\\
y^{(pr)}\\
z^{(pr)}
\end{array}\right]-\boldsymbol{\mu}\right)^{T}\boldsymbol{\Sigma}^{-1}\left(\left[\begin{array}{c}
x^{(pr)}\\
y^{(pr)}\\
z^{(pr)}
\end{array}\right]-\boldsymbol{\mu}\right)\right)
\]

\end_inset


\end_layout

\begin_layout Standard
The log of which is:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
-\frac{3}{2}\log\left(2\pi\right)-\frac{1}{2}\log\left(\sigma_{p}^{2}\tau_{r}^{2}\sigma^{2}\right)-\frac{1}{2}\left(\frac{1}{\sigma^{2}}\left(z^{(pr)^{2}}+2y^{(pr)}z^{(pr)}-2x^{(pr)}z^{(pr)}+y^{(pr)^{2}}-2x^{(pr)}y^{(pr)}+x^{(pr)^{2}}\right)\right)+
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
-\frac{1}{2}\left(\frac{1}{\tau_{r}^{2}}\left(z^{(pr)^{2}}-2\nu_{r}z^{(pr)}+\nu_{r}^{2}\right)+\frac{1}{\sigma_{p}^{2}}\left(y^{(pr)^{2}}-2\mu_{p}y^{(pr)}+\mu_{p}^{2}\right)\right)
\]

\end_inset


\end_layout

\begin_layout Standard
The only parts relevant to the argmax operation are:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
-\frac{1}{2}\left(\log\left(\sigma_{p}^{2}\tau_{r}^{2}\right)+\frac{1}{\tau_{r}^{2}}\left(z^{(pr)}-\nu_{r}\right)^{2}+\frac{1}{\sigma_{p}^{2}}\left(y^{(pr)}-\mu_{p}\right)^{2}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
Returning the the main expression:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\arg\max_{\mu_{p},\nu_{r},\sigma_{p}^{2},\tau_{r}^{2}}\sum_{p}\sum_{r}\mathbb{E}_{(y^{(pr)},z^{(pr)})\sim Q_{pr}}-\frac{1}{2}\left(\log\left(\sigma_{p}^{2}\tau_{r}^{2}\right)+\frac{1}{\tau_{r}^{2}}\left(z^{(pr)}-\nu_{r}\right)^{2}+\frac{1}{\sigma_{p}^{2}}\left(y^{(pr)}-\mu_{p}\right)^{2}\right)=
\]

\end_inset


\end_layout

\begin_layout Standard
The expectation of the 
\begin_inset Formula $\frac{1}{\tau_{r}^{2}}\left(z^{(pr)}-\nu_{r}\right)^{2}$
\end_inset

 term, using the mean and covariance matrix from (a), and using the fact
 that 
\begin_inset Formula $\mathbb{E}((x-a)^{2})=\mathbb{E}(x^{2}-2ax-a^{2})=\mathbb{E}x^{2}-2a\mathbb{E}x-a^{2}=\sigma_{x}^{2}+\mu_{x}^{2}-2a\mu_{x}-a^{2}=\sigma_{x}^{2}+(\mu_{x}-a)^{2}$
\end_inset

, is:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\frac{1}{\tau_{r}^{2}}\left(\tilde{\tau}_{r}^{2}-\frac{\tilde{\tau}_{r}^{4}}{\sigma^{2}+\tilde{\sigma}_{p}^{2}+\tilde{\tau}_{r}^{2}}+\left(\tilde{\nu}_{r}+\frac{\tilde{\tau}_{r}^{2}(x^{(pr)}-\tilde{\nu}_{r}-\tilde{\mu}_{p})}{\sigma^{2}+\tilde{\sigma}_{p}^{2}+\tilde{\tau}_{r}^{2}}-\nu_{r}\right)^{2}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
Similiarly the expectation of the 
\begin_inset Formula $\frac{1}{\sigma_{p}^{2}}\left(y^{(pr)}-\mu_{p}\right)^{2}$
\end_inset

 term is:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\frac{1}{\sigma_{p}^{2}}\left(\tilde{\sigma}_{p}^{2}-\frac{\tilde{\sigma}_{p}^{4}}{\sigma^{2}+\tilde{\sigma}_{p}^{2}+\tilde{\tau}_{r}^{2}}+\left(\tilde{\mu}_{p}+\frac{\tilde{\sigma}_{p}^{2}(x^{(pr)}-\tilde{\nu}_{r}-\tilde{\mu}_{p})}{\sigma^{2}+\tilde{\sigma}_{p}^{2}+\tilde{\tau}_{r}^{2}}-\mu_{p}\right)^{2}\right)=
\]

\end_inset


\end_layout

\begin_layout Standard
The variables with a tilde denote those determined in the E-step, that are
 not subject to maximization.
 Taking these into account, and removing the 
\begin_inset Formula $-\frac{1}{2}$
\end_inset

 factor, and changing max to min:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\arg\min_{\mu_{p},\nu_{r},\sigma_{p}^{2},\tau_{r}^{2}}\sum_{p}\sum_{r}\log\sigma_{p}^{2}+\frac{1}{\sigma_{p}^{2}}\left(\tilde{\sigma}_{p}^{2}-\frac{\tilde{\sigma}_{p}^{4}}{\sigma^{2}+\tilde{\sigma}_{p}^{2}+\tilde{\tau}_{r}^{2}}+\left(\tilde{\mu}_{p}+\frac{\tilde{\sigma}_{p}^{2}(x^{(pr)}-\tilde{\nu}_{r}-\tilde{\mu}_{p})}{\sigma^{2}+\tilde{\sigma}_{p}^{2}+\tilde{\tau}_{r}^{2}}-\mu_{p}\right)^{2}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
+\log\tau_{r}^{2}+\frac{1}{\tau_{r}^{2}}\left(\tilde{\tau}_{r}^{2}-\frac{\tilde{\tau}_{r}^{4}}{\sigma^{2}+\tilde{\sigma}_{p}^{2}+\tilde{\tau}_{r}^{2}}+\left(\tilde{\nu}_{r}+\frac{\tilde{\tau}_{r}^{2}(x^{(pr)}-\tilde{\nu}_{r}-\tilde{\mu}_{p})}{\sigma^{2}+\tilde{\sigma}_{p}^{2}+\tilde{\tau}_{r}^{2}}-\nu_{r}\right)^{2}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
Partial derivative with respect to 
\begin_inset Formula $\mu_{p'}$
\end_inset

, set to 0:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\sum_{p}\sum_{r}\frac{1}{\sigma_{p}^{2}}\left(-2\left(\tilde{\mu}_{p}+\frac{\tilde{\sigma}_{p}^{2}(x^{(pr)}-\tilde{\nu}_{r}-\tilde{\mu}_{p})}{\sigma^{2}+\tilde{\sigma}_{p}^{2}+\tilde{\tau}_{r}^{2}}-\mu_{p}\right)\boldsymbol{1}\{p'=p\}\right)=0
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\sum_{r}\sum_{p}\frac{1}{\sigma_{p}^{2}}\left(\tilde{\mu}_{p}+\frac{\tilde{\sigma}_{p}^{2}(x^{(pr)}-\tilde{\nu}_{r}-\tilde{\mu}_{p})}{\sigma^{2}+\tilde{\sigma}_{p}^{2}+\tilde{\tau}_{r}^{2}}-\mu_{p}\right)\boldsymbol{1}\{p'=p\}=0
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\frac{1}{\sigma_{p'}^{2}}\sum_{r}\left(\tilde{\mu}_{p'}+\frac{\tilde{\sigma}_{p'}^{2}(x^{(p'r)}-\tilde{\nu}_{r}-\tilde{\mu}_{p'})}{\sigma^{2}+\tilde{\sigma}_{p'}^{2}+\tilde{\tau}_{r}^{2}}-\mu_{p'}\right)=0
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\sum_{r}\left(\tilde{\mu}_{p'}+\frac{\tilde{\sigma}_{p'}^{2}(x^{(p'r)}-\tilde{\nu}_{r}-\tilde{\mu}_{p'})}{\sigma^{2}+\tilde{\sigma}_{p'}^{2}+\tilde{\tau}_{r}^{2}}-\mu_{p'}\right)=0
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\mu_{p'}=\frac{1}{R}\sum_{r}\left(\tilde{\mu}_{p'}+\frac{\tilde{\sigma}_{p'}^{2}(x^{(p'r)}-\tilde{\nu}_{r}-\tilde{\mu}_{p'})}{\sigma^{2}+\tilde{\sigma}_{p'}^{2}+\tilde{\tau}_{r}^{2}}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
And reindexing from p' to p:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\mu_{p}=\frac{1}{R}\sum_{r=1}^{R}\left(\tilde{\mu}_{p}+\frac{\tilde{\sigma}_{p}^{2}(x^{(pr)}-\tilde{\nu}_{r}-\tilde{\mu}_{p})}{\sigma^{2}+\tilde{\sigma}_{p}^{2}+\tilde{\tau}_{r}^{2}}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\mu_{p}=\tilde{\mu}_{p}+\frac{1}{R}\sum_{r=1}^{R}\left(\frac{\tilde{\sigma}_{p}^{2}(x^{(pr)}-\tilde{\nu}_{r}-\tilde{\mu}_{p})}{\sigma^{2}+\tilde{\sigma}_{p}^{2}+\tilde{\tau}_{r}^{2}}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
Partial derivative with respect to 
\begin_inset Formula $\nu_{r'}$
\end_inset

, set to 0:
\end_layout

\begin_layout Standard

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
\begin_inset Formula 
\[
\sum_{p}\sum_{r}\frac{1}{\tau_{r}^{2}}\left(-2\left(\tilde{\nu}_{r}+\frac{\tilde{\tau}_{r}^{2}(x^{(pr)}-\tilde{\nu}_{r}-\tilde{\mu}_{p})}{\sigma^{2}+\tilde{\sigma}_{p}^{2}+\tilde{\tau}_{r}^{2}}-\nu_{r}\right)\boldsymbol{1}\{r'=r\}\right)=0
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\sum_{p}\sum_{r}\frac{1}{\tau_{r}^{2}}\left(\tilde{\nu}_{r}+\frac{\tilde{\tau}_{r}^{2}(x^{(pr)}-\tilde{\nu}_{r}-\tilde{\mu}_{p})}{\sigma^{2}+\tilde{\sigma}_{p}^{2}+\tilde{\tau}_{r}^{2}}-\nu_{r}\right)\boldsymbol{1}\{r'=r\}=0
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\frac{1}{\tau_{r'}^{2}}\sum_{p}\left(\tilde{\nu}_{r'}+\frac{\tilde{\tau}_{r'}^{2}(x^{(pr')}-\tilde{\nu}_{r'}-\tilde{\mu}_{p})}{\sigma^{2}+\tilde{\sigma}_{p}^{2}+\tilde{\tau}_{r'}^{2}}-\nu_{r'}\right)=0
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\sum_{p}\left(\tilde{\nu}_{r'}+\frac{\tilde{\tau}_{r'}^{2}(x^{(pr')}-\tilde{\nu}_{r'}-\tilde{\mu}_{p})}{\sigma^{2}+\tilde{\sigma}_{p}^{2}+\tilde{\tau}_{r'}^{2}}-\nu_{r'}\right)=0
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\nu_{r'}=\frac{1}{P}\sum_{p=1}^{P}\left(\tilde{\nu}_{r'}+\frac{\tilde{\tau}_{r'}^{2}(x^{(pr')}-\tilde{\nu}_{r'}-\tilde{\mu}_{p})}{\sigma^{2}+\tilde{\sigma}_{p}^{2}+\tilde{\tau}_{r'}^{2}}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
And reindexing from r' to r:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\nu_{r}=\frac{1}{P}\sum_{p=1}^{P}\left(\tilde{\nu}_{r}+\frac{\tilde{\tau}_{r}^{2}(x^{(pr)}-\tilde{\nu}_{r}-\tilde{\mu}_{p})}{\sigma^{2}+\tilde{\sigma}_{p}^{2}+\tilde{\tau}_{r}^{2}}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\nu_{r}=\tilde{\nu}_{r}+\frac{1}{P}\sum_{p=1}^{P}\left(\frac{\tilde{\tau}_{r}^{2}(x^{(pr)}-\tilde{\nu}_{r}-\tilde{\mu}_{p})}{\sigma^{2}+\tilde{\sigma}_{p}^{2}+\tilde{\tau}_{r}^{2}}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
Partial derivative with respect to 
\begin_inset Formula $\sigma_{p'}^{2}$
\end_inset

, set to 0:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\sum_{p}\sum_{r}\boldsymbol{1}\{p'=p\}\left[\frac{1}{\sigma_{p}^{2}}-\frac{1}{\sigma_{p}^{4}}\left(\tilde{\sigma}_{p}^{2}-\frac{\tilde{\sigma}_{p}^{4}}{\sigma^{2}+\tilde{\sigma}_{p}^{2}+\tilde{\tau}_{r}^{2}}+\left(\tilde{\mu}_{p}+\frac{\tilde{\sigma}_{p}^{2}(x^{(pr)}-\tilde{\nu}_{r}-\tilde{\mu}_{p})}{\sigma^{2}+\tilde{\sigma}_{p}^{2}+\tilde{\tau}_{r}^{2}}-\mu_{p}\right)^{2}\right)\right]=0
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\sum_{r}\left(\frac{1}{\sigma_{p'}^{2}}-\frac{1}{\sigma_{p'}^{4}}\left(\tilde{\sigma}_{p'}^{2}-\frac{\tilde{\sigma}_{p'}^{4}}{\sigma^{2}+\tilde{\sigma}_{p'}^{2}+\tilde{\tau}_{r}^{2}}+\left(\tilde{\mu}_{p'}+\frac{\tilde{\sigma}_{p'}^{2}(x^{(p'r)}-\tilde{\nu}_{r}-\tilde{\mu}_{p'})}{\sigma^{2}+\tilde{\sigma}_{p'}^{2}+\tilde{\tau}_{r}^{2}}-\mu_{p'}\right)^{2}\right)\right)=0
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\sum_{r}\left(\sigma_{p'}^{2}-\left(\tilde{\sigma}_{p'}^{2}-\frac{\tilde{\sigma}_{p'}^{4}}{\sigma^{2}+\tilde{\sigma}_{p'}^{2}+\tilde{\tau}_{r}^{2}}+\left(\tilde{\mu}_{p'}+\frac{\tilde{\sigma}_{p'}^{2}(x^{(p'r)}-\tilde{\nu}_{r}-\tilde{\mu}_{p'})}{\sigma^{2}+\tilde{\sigma}_{p'}^{2}+\tilde{\tau}_{r}^{2}}-\mu_{p'}\right)^{2}\right)\right)=0
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\sigma_{p'}^{2}=\frac{1}{R}\sum_{r=1}^{R}\left(\tilde{\sigma}_{p'}^{2}-\frac{\tilde{\sigma}_{p'}^{4}}{\sigma^{2}+\tilde{\sigma}_{p'}^{2}+\tilde{\tau}_{r}^{2}}+\left(\tilde{\mu}_{p'}+\frac{\tilde{\sigma}_{p'}^{2}(x^{(p'r)}-\tilde{\nu}_{r}-\tilde{\mu}_{p'})}{\sigma^{2}+\tilde{\sigma}_{p'}^{2}+\tilde{\tau}_{r}^{2}}-\mu_{p'}\right)^{2}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
And reindexing from p' to p:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\sigma_{p}^{2}=\frac{1}{R}\sum_{r=1}^{R}\left(\tilde{\sigma}_{p}^{2}-\frac{\tilde{\sigma}_{p}^{4}}{\sigma^{2}+\tilde{\sigma}_{p}^{2}+\tilde{\tau}_{r}^{2}}+\left(\tilde{\mu}_{p}+\frac{\tilde{\sigma}_{p}^{2}(x^{(pr)}-\tilde{\nu}_{r}-\tilde{\mu}_{p})}{\sigma^{2}+\tilde{\sigma}_{p}^{2}+\tilde{\tau}_{r}^{2}}-\mu_{p}\right)^{2}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\sigma_{p}^{2}=\tilde{\sigma}_{p}^{2}+\frac{1}{R}\sum_{r=1}^{R}\left(-\frac{\tilde{\sigma}_{p}^{4}}{\sigma^{2}+\tilde{\sigma}_{p}^{2}+\tilde{\tau}_{r}^{2}}+\left(\frac{\tilde{\sigma}_{p}^{2}(x^{(pr)}-\tilde{\nu}_{r}-\tilde{\mu}_{p})}{\sigma^{2}+\tilde{\sigma}_{p}^{2}+\tilde{\tau}_{r}^{2}}-(\mu_{p}-\tilde{\mu}_{p})\right)^{2}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
Where 
\begin_inset Formula $\mu_{p}$
\end_inset

 is the new value derived before.
\end_layout

\begin_layout Standard
Partial derivative with respect to 
\begin_inset Formula $\tau_{r'}^{2}$
\end_inset

, set to 0:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\sum_{p}\sum_{r}\boldsymbol{1}\{r'=r\}\left[\frac{1}{\tau_{r}^{2}}-\frac{1}{\tau_{r}^{4}}\left(\tilde{\tau}_{r}^{2}-\frac{\tilde{\tau}_{r}^{4}}{\sigma^{2}+\tilde{\sigma}_{p}^{2}+\tilde{\tau}_{r}^{2}}+\left(\tilde{\nu}_{r}+\frac{\tilde{\tau}_{r}^{2}(x^{(pr)}-\tilde{\nu}_{r}-\tilde{\mu}_{p})}{\sigma^{2}+\tilde{\sigma}_{p}^{2}+\tilde{\tau}_{r}^{2}}-\nu_{r}\right)^{2}\right)\right]=0
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\sum_{p}\left(\frac{1}{\tau_{r'}^{2}}-\frac{1}{\tau_{r'}^{4}}\left(\tilde{\tau}_{r'}^{2}-\frac{\tilde{\tau}_{r'}^{4}}{\sigma^{2}+\tilde{\sigma}_{p}^{2}+\tilde{\tau}_{r'}^{2}}+\left(\tilde{\nu}_{r'}+\frac{\tilde{\tau}_{r'}^{2}(x^{(pr')}-\tilde{\nu}_{r'}-\tilde{\mu}_{p})}{\sigma^{2}+\tilde{\sigma}_{p}^{2}+\tilde{\tau}_{r'}^{2}}-\nu_{r'}\right)^{2}\right)\right)=0
\]

\end_inset


\end_layout

\begin_layout Standard

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
\begin_inset Formula 
\[
\sum_{p}\left(\tau_{r'}^{2}-\left(\tilde{\tau}_{r'}^{2}-\frac{\tilde{\tau}_{r'}^{4}}{\sigma^{2}+\tilde{\sigma}_{p}^{2}+\tilde{\tau}_{r'}^{2}}+\left(\tilde{\nu}_{r'}+\frac{\tilde{\tau}_{r'}^{2}(x^{(pr')}-\tilde{\nu}_{r'}-\tilde{\mu}_{p})}{\sigma^{2}+\tilde{\sigma}_{p}^{2}+\tilde{\tau}_{r'}^{2}}-\nu_{r'}\right)^{2}\right)\right)=0
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\tau_{r'}^{2}=\frac{1}{P}\sum_{p=1}^{P}\left(\tilde{\tau}_{r'}^{2}-\frac{\tilde{\tau}_{r'}^{4}}{\sigma^{2}+\tilde{\sigma}_{p}^{2}+\tilde{\tau}_{r'}^{2}}+\left(\tilde{\nu}_{r'}+\frac{\tilde{\tau}_{r'}^{2}(x^{(pr')}-\tilde{\nu}_{r'}-\tilde{\mu}_{p})}{\sigma^{2}+\tilde{\sigma}_{p}^{2}+\tilde{\tau}_{r'}^{2}}-\nu_{r'}\right)^{2}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
And reindexing from r' to r:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\tau_{r}^{2}=\frac{1}{P}\sum_{p=1}^{P}\left(\tilde{\tau}_{r}^{2}-\frac{\tilde{\tau}_{r}^{4}}{\sigma^{2}+\tilde{\sigma}_{p}^{2}+\tilde{\tau}_{r}^{2}}+\left(\tilde{\nu}_{r}+\frac{\tilde{\tau}_{r}^{2}(x^{(pr)}-\tilde{\nu}_{r}-\tilde{\mu}_{p})}{\sigma^{2}+\tilde{\sigma}_{p}^{2}+\tilde{\tau}_{r}^{2}}-\nu_{r}\right)^{2}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\tau_{r}^{2}=\tilde{\tau}_{r}^{2}+\frac{1}{P}\sum_{p=1}^{P}\left(-\frac{\tilde{\tau}_{r}^{4}}{\sigma^{2}+\tilde{\sigma}_{p}^{2}+\tilde{\tau}_{r}^{2}}+\left(\frac{\tilde{\tau}_{r}^{2}(x^{(pr)}-\tilde{\nu}_{r}-\tilde{\mu}_{p})}{\sigma^{2}+\tilde{\sigma}_{p}^{2}+\tilde{\tau}_{r}^{2}}-(\nu_{r}-\tilde{\nu}_{r})\right)^{2}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
Where 
\begin_inset Formula $\nu_{_{r}}$
\end_inset

 is the new value derived before.
\end_layout

\begin_layout Standard
Rewritten in terms of updates to the parameters:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\Delta\mu_{p}\leftarrow\frac{1}{R}\sum_{r=1}^{R}\left(\frac{\sigma_{p}^{2}(x^{(pr)}-\nu_{r}-\mu_{p})}{\sigma^{2}+\sigma_{p}^{2}+\tau_{r}^{2}}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\Delta\nu_{r}\leftarrow\frac{1}{P}\sum_{p=1}^{P}\left(\frac{\tau_{r}^{2}(x^{(pr)}-\nu_{r}-\mu_{p})}{\sigma^{2}+\sigma_{p}^{2}+\tau_{r}^{2}}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\sigma_{p}^{2^{(\text{new})}}\leftarrow\sigma_{p}^{2}+\frac{1}{R}\sum_{r=1}^{R}\left(-\frac{\sigma_{p}^{4}}{\sigma^{2}+\sigma_{p}^{2}+\tau_{r}^{2}}+\left(\frac{\sigma_{p}^{2}(x^{(pr)}-\nu_{r}-\mu_{p})}{\sigma^{2}+\sigma_{p}^{2}+\tau_{r}^{2}}-\Delta\mu_{p}\right)^{2}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\tau_{r}^{2^{(\text{new})}}\leftarrow\tau_{r}^{2}+\frac{1}{P}\sum_{p=1}^{P}\left(-\frac{\tau_{r}^{4}}{\sigma^{2}+\sigma_{p}^{2}+\tau_{r}^{2}}+\left(\frac{\tau_{r}^{2}(x^{(pr)}-\nu_{r}-\mu_{p})}{\sigma^{2}+\sigma_{p}^{2}+\tau_{r}^{2}}-\Delta\nu_{r}\right)^{2}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\mu_{p}^{(\text{new})}\leftarrow\mu_{p}+\Delta\mu_{p}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\nu_{r}^{(\text{new})}\leftarrow\nu_{r}+\Delta\nu_{r}
\]

\end_inset


\end_layout

\begin_layout Section
KL divergence and Maximum Likelihood
\end_layout

\begin_layout Subsection*
(a)
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
0=-\log1=-\log\sum_{x}Q(x)=-\log\sum_{x}P(x)\frac{Q(x)}{P(x)}=-\log\mathbb{E}_{P}\frac{Q(x)}{P(x)}\le\mathbb{E}_{P}\left(-\log\frac{Q(x)}{P(x)}\right)=
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=-\sum_{x}P(x)\log\frac{Q(x)}{P(x)}=\sum_{x}P(x)\log\frac{P(x)}{Q(x)}=KL(P||Q)
\]

\end_inset


\end_layout

\begin_layout Standard
The inequality is due to 
\begin_inset Formula $-\log(x)$
\end_inset

 being a convex function and the use of Jensen's inequality, resulting in
 
\begin_inset Formula $KL(P||Q)\ge0$
\end_inset

 for any P,Q.
\end_layout

\begin_layout Standard
Also by Jensen's inequality, is that equality holds if and only if the variable
 in question, in this case, 
\begin_inset Formula $Q(x)/P(x)$
\end_inset

 is a constant.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\forall x,\; Q(x)/P(x)=c
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
Q(x)=cP(x)
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
1=\sum_{x}Q(x)=\sum_{x}cP(x)=c\sum_{x}P(x)=c
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\text{therefore }\forall x,\; Q(x)=P(x)\text{ iff. the equality holds}
\]

\end_inset

 
\end_layout

\begin_layout Standard
When the equality holds, 
\begin_inset Formula $KL(P||Q)=0$
\end_inset

, and this will occur if and only if P=Q.
\end_layout

\begin_layout Subsection*
(b)
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
KL(P(X,Y)||Q(X,Y))=\sum_{y}\sum_{x}P(x,y)\log\frac{P(x,y)}{Q(x,y)}=\sum_{y}\sum_{x}P(x)P(y\mid x)\log\frac{P(x)P(y\mid x)}{Q(x)Q(y\mid x)}=
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=\sum_{y}\sum_{x}P(x)P(y\mid x)\log\frac{P(x)}{Q(x)}+\sum_{y}\sum_{x}P(x)P(y\mid x)\log\frac{P(y\mid x)}{Q(y\mid x)}=
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=\sum_{x}P(x)\log\frac{P(x)}{Q(x)}\left(\sum_{y}P(y\mid x)\right)+\sum_{x}P(x)\left(\sum_{y}P(y\mid x)\log\frac{P(y\mid x)}{Q(y\mid x)}\right)=
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=\sum_{x}P(x)\log\frac{P(x)}{Q(x)}+\sum_{x}P(x)\left(\sum_{y}P(y\mid x)\log\frac{P(y\mid x)}{Q(y\mid x)}\right)=
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=KL(P(X)||Q(X))+KL(P(Y\mid X)||Q(Y\mid X))
\]

\end_inset


\end_layout

\begin_layout Subsection*
(c)
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\arg\min_{\theta}KL(\hat{P}||P_{\theta})=\arg\min_{\theta}\sum_{x}\hat{P}(x)\log\frac{\hat{P}(x)}{P_{\theta}(x)}=
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=\arg\min_{\theta}\sum_{x}\left(\hat{P}(x)\log\hat{P}(x)-\hat{P}(x)\log P_{\theta}(x)\right)=\arg\min_{\theta}\sum_{x}\left(-\hat{P}(x)\log P_{\theta}(x)\right)=
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=\arg\max_{\theta}\sum_{x}\hat{P}(x)\log P_{\theta}(x)=\arg\max_{\theta}\sum_{x}\frac{1}{m}\sum_{i=1}^{m}\boldsymbol{1}\{x^{(i)}=x\}P_{\theta}(x)=
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=\arg\max_{\theta}\frac{1}{m}\sum_{i=1}^{m}\left(\sum_{x}\boldsymbol{1}\{x^{(i)}=x\}P_{\theta}(x)\right)=\arg\max_{\theta}\frac{1}{m}\sum_{i=1}^{m}P_{\theta}(x^{(i)})=
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=\arg\max_{\theta}\sum_{i=1}^{m}P_{\theta}(x^{(i)})
\]

\end_inset


\end_layout

\begin_layout Section
K-means for compression
\end_layout

\begin_layout Subsection*
(a)
\end_layout

\begin_layout Standard
Entering:
\end_layout

\begin_layout Standard
\begin_inset listings
inline false
status open

\begin_layout Plain Layout

A = double(imread('mandrill-large.tiff'));
\end_layout

\begin_layout Plain Layout

imshow(uint8(round(A)));
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Resulted in displaying the image:
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename p5_a.png
	scale 50

\end_inset


\end_layout

\begin_layout Subsection*
(b)
\end_layout

\begin_layout Standard
K-means with K=16 was implemented and followed the following learning curve:
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename distort.png
	scale 75

\end_inset


\end_layout

\begin_layout Standard
Convergence was reached in 81 iterations (time to convergence may vary due
 to random initialization).
\end_layout

\begin_layout Subsection*
(c)
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename mandrill-large.tiff

\end_inset


\end_layout

\begin_layout Standard
This is the original image.
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename kmeans_image.tiff

\end_inset


\end_layout

\begin_layout Standard
This is the image after applying k-means to reduce the amount of colors
 in it.
 The image lost some of its crispness, and compression artifacts can be
 seen in the colors of the eyes, and in the yellowish region on the bottom
 left that turned into a solid color.
\end_layout

\begin_layout Standard
\begin_inset CommandInset include
LatexCommand lstinputlisting
filename "p5.m"
lstparams "language=Matlab"

\end_inset


\end_layout

\begin_layout Subsection*
(d)
\end_layout

\begin_layout Standard
If the original image had 
\begin_inset Formula $N$
\end_inset

 pixels, each represented by 24 bits (8 bits per channel, 3 channels), then
 the total size is 
\begin_inset Formula $24N$
\end_inset

 bits.
 The compressed image with 16 colors can be represented by a 4 bit number
 for each pixel, where the numbers from 0 to 15 each represent one of the
 colors, resulting in 
\begin_inset Formula $4N$
\end_inset

 bits.
 The values of the corresponding colors must be encoded too, 
\begin_inset Formula $16\times24$
\end_inset

 bits, but if N is large then this can be neglected in the ratio.
 The approximate factor is 
\begin_inset Formula $\frac{24N}{4N}=6$
\end_inset

.
 Compression by a factor of 6.
\end_layout

\end_body
\end_document
